{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de predição de links com embeddings de nodos baseados em caminhadas aleatórias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/link-prediction/homogeneous-comparison-link-prediction.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/link-prediction/homogeneous-comparison-link-prediction.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook foi desenvolvido como parte da disciplina de \"Análise de Redes Sociais\" na faculdade. Ele demonstra a comparação do desempenho de predição de links utilizando embeddings aprendidos por Node2Vec [1], Attri2Vec [2], GraphSAGE [3] e GCN [4] no dataset Cora, sob a mesma configuração de divisão de arestas em treino e teste. Node2Vec e Attri2Vec aprendem ao capturar a similaridade de nós no contexto de caminhadas aleatórias. GraphSAGE e GCN aprendem de forma não supervisionada, representando nós que coocorrem em caminhadas aleatórias curtas de forma próxima no espaço de embedding.\n",
    "\n",
    "O objetivo é abordar a predição de links como um problema de aprendizado supervisionado em cima das representações/embeddings de nós. Após obter os embeddings, um classificador binário pode ser usado para prever a existência, ou não, de um link entre dois nós do grafo. Diversos hiperparâmetros podem influenciar na obtenção do melhor classificador de links - esta demonstração incorpora a seleção de modelos no pipeline para escolher o melhor operador binário a ser aplicado em um par de embeddings de nós.\n",
    "\n",
    "O processo está dividido em quatro etapas principais:\n",
    "\n",
    "1. Obter os embeddings para cada nó\n",
    "2. Para cada conjunto de hiperparâmetros, treinar um classificador\n",
    "3. Selecionar o classificador com melhor desempenho\n",
    "4. Avaliar o classificador selecionado em dados não vistos para validar sua capacidade de generalização\n",
    "\n",
    "**Referências:**\n",
    "\n",
    "[1] Node2Vec: Scalable Feature Learning for Networks. A. Grover, J. Leskovec. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2016.\n",
    "\n",
    "[2] Attributed Network Embedding via Subspace Discovery. D. Zhang, Y. Jie, X. Zhu e C. Zhang. Data Mining and Knowledge Discovery, 2019.\n",
    "\n",
    "[3] Inductive Representation Learning on Large Graphs. W.L. Hamilton, R. Ying, e J. Leskovec. Neural Information Processing Systems (NIPS), 2017.\n",
    "\n",
    "[4] Graph Convolutional Networks (GCN): Semi-Supervised Classification with Graph Convolutional Networks. Thomas N. Kipf, Max Welling. International Conference on Learning Representations (ICLR), 2017.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "outputs": [],
   "source": [
    "# install StellarGraph if running on Google Colab\n",
    "#import sys\n",
    "#if 'google.colab' in sys.modules:\n",
    "#  %pip install -q stellargraph[demos]==1.3.0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "VersionCheck"
    ]
   },
   "outputs": [],
   "source": [
    "# verify that we're using the correct version of StellarGraph for this notebook\n",
    "#import stellargraph as sg\n",
    "\n",
    "#try:\n",
    "#    sg.utils.validate_notebook_version(\"1.3.0b\")\n",
    "#except AttributeError:\n",
    "#    raise ValueError(\n",
    "#        f\"This notebook requires StellarGraph version 1.3.0b, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
    "#    ) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 19:20:35.630491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 19:20:35.772750: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 19:20:35.775962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-27 19:20:35.775975: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-11-27 19:20:36.254986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-27 19:20:36.255058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-27 19:20:36.255062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-11-27 19:20:36.665437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-11-27 19:20:36.665452: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-11-27 19:20:36.665462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hellsing): /proc/driver/nvidia/version does not exist\n",
      "2024-11-27 19:20:36.665732: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import isclose\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stellargraph import StellarGraph, datasets\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "import stellargraph as sg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do conjunto de dados\n",
    "\n",
    "O dataset Cora é uma rede homogênea onde todos os nós representam artigos, e as arestas entre os nós são links de citação, por exemplo, o artigo A cita o artigo B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "DataLoadingLinks"
    ]
   },
   "source": [
    "(See [the \"Loading from Pandas\" demo](../basics/loading-pandas.ipynb) for details on how data can be loaded.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "DataLoading"
    ]
   },
   "outputs": [],
   "source": [
    "#dataset = datasets.Cora()\n",
    "#display(HTML(dataset.description))\n",
    "#graph, _ = dataset.load(largest_connected_component_only=True, str_node_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import stellargraph as sg\n",
    "\n",
    "## Carregue o grafo do arquivo\n",
    "#with open(\"meu_grafo.gpickle\", \"rb\") as f:\n",
    "#    G = pickle.load(f)\n",
    "    \n",
    "#graph = sg.StellarGraph.from_networkx(G)\n",
    "#graph.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = nx.read_graphml('../graphs/coauthorship_graph.xml', node_type=str)\n",
    "graph = sg.StellarGraph.from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3307"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7748"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 3307, Edges: 7748\n",
      "\n",
      " Node types:\n",
      "  default: [3307]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [7748]\n",
      "        Weights: range=[1, 631], mean=4.51962, std=13.8279\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graph.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir divisões dos dados de entrada\n",
    "\n",
    "Precisamos dividir os dados cuidadosamente para evitar vazamento de informações e avaliar os algoritmos corretamente:\n",
    "\n",
    "* Para calcular os embeddings dos nós, um **Grafo de Treinamento** (`graph_train`)\n",
    "* Para treinar os classificadores, um **Conjunto de Treinamento do Classificador** (`examples_train`) com arestas positivas e negativas que não foram usadas para calcular os embeddings dos nós\n",
    "* Para escolher o melhor classificador, um **Conjunto de Teste para Seleção de Modelo** (`examples_model_selection`) com arestas positivas e negativas que não foram usadas para calcular os embeddings dos nós ou para treinar o classificador\n",
    "* Para a avaliação final, com os embeddings dos nós aprendidos a partir do **Grafo de Treinamento** (`graph_train`), o melhor classificador escolhido é aplicado a um **Conjunto de Teste** (`examples_test`) com arestas positivas e negativas que não foram usadas para calcular os embeddings dos nós, treinar o classificador ou selecionar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo de Teste\n",
    "\n",
    "Começamos com o grafo completo e utilizamos a classe `EdgeSplitter` para produzir:\n",
    "\n",
    "* Grafo de Teste\n",
    "* Conjunto de teste com exemplos de links positivos/negativos\n",
    "\n",
    "O Grafo de Teste é o grafo reduzido que obtemos ao remover o conjunto de teste de links do grafo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 774 positive and 774 negative edges. **\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 3307, Edges: 6974\n",
      "\n",
      " Node types:\n",
      "  default: [3307]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [6974]\n",
      "        Weights: range=[1, 631], mean=4.58589, std=14.2684\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "# Definir um divisor de arestas no grafo original:\n",
    "edge_splitter_test = EdgeSplitter(graph)\n",
    "\n",
    "# Amostra aleatoriamente uma fração p=0.1 de todos os links positivos, e o mesmo número de links negativos, do grafo,\n",
    "# obtendo o grafo reduzido graph_test com os links amostrados removidos:\n",
    "graph_test, examples_test, labels_test = edge_splitter_test.train_test_split(\n",
    "    p=0.1, method=\"global\"\n",
    ")\n",
    "\n",
    "print(graph_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo de Treinamento\n",
    "\n",
    "Desta vez, utilizamos a classe `EdgeSplitter` no Grafo de Teste e realizamos uma divisão de treino/teste nos exemplos para produzir:\n",
    "\n",
    "* Grafo de Treinamento\n",
    "* Conjunto de treinamento com exemplos de links\n",
    "* Conjunto de exemplos de links para seleção de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 697 positive and 697 negative edges. **\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 3307, Edges: 6277\n",
      "\n",
      " Node types:\n",
      "  default: [3307]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [6277]\n",
      "        Weights: range=[1, 631], mean=4.56747, std=14.3531\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "# Realizar o mesmo processo para calcular um subconjunto de treinamento a partir do grafo de teste\n",
    "edge_splitter_train = EdgeSplitter(graph_test)\n",
    "graph_train, examples, labels = edge_splitter_train.train_test_split(\n",
    "    p=0.1, method=\"global\"\n",
    ")\n",
    "(\n",
    "    examples_train,\n",
    "    examples_model_selection,\n",
    "    labels_train,\n",
    "    labels_model_selection,\n",
    ") = train_test_split(examples, labels, train_size=0.75, test_size=0.25)\n",
    "\n",
    "print(graph_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a summary of the different splits that have been created in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Examples</th>\n",
       "      <th>Hidden from</th>\n",
       "      <th>Picked from</th>\n",
       "      <th>Use</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Set</th>\n",
       "      <td>1045</td>\n",
       "      <td>Train Graph</td>\n",
       "      <td>Test Graph</td>\n",
       "      <td>Train the Link Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Selection</th>\n",
       "      <td>349</td>\n",
       "      <td>Train Graph</td>\n",
       "      <td>Test Graph</td>\n",
       "      <td>Select the best Link Classifier model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test set</th>\n",
       "      <td>1548</td>\n",
       "      <td>Test Graph</td>\n",
       "      <td>Full Graph</td>\n",
       "      <td>Evaluate the best Link Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Number of Examples  Hidden from Picked from  \\\n",
       "Split                                                          \n",
       "Training Set                   1045  Train Graph  Test Graph   \n",
       "Model Selection                 349  Train Graph  Test Graph   \n",
       "Test set                       1548   Test Graph  Full Graph   \n",
       "\n",
       "                                                   Use  \n",
       "Split                                                   \n",
       "Training Set                 Train the Link Classifier  \n",
       "Model Selection  Select the best Link Classifier model  \n",
       "Test set             Evaluate the best Link Classifier  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            \"Training Set\",\n",
    "            len(examples_train),\n",
    "            \"Train Graph\",\n",
    "            \"Test Graph\",\n",
    "            \"Train the Link Classifier\",\n",
    "        ),\n",
    "        (\n",
    "            \"Model Selection\",\n",
    "            len(examples_model_selection),\n",
    "            \"Train Graph\",\n",
    "            \"Test Graph\",\n",
    "            \"Select the best Link Classifier model\",\n",
    "        ),\n",
    "        (\n",
    "            \"Test set\",\n",
    "            len(examples_test),\n",
    "            \"Test Graph\",\n",
    "            \"Full Graph\",\n",
    "            \"Evaluate the best Link Classifier\",\n",
    "        ),\n",
    "    ],\n",
    "    columns=(\"Split\", \"Number of Examples\", \"Hidden from\", \"Picked from\", \"Use\"),\n",
    ").set_index(\"Split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar o gerador de caminhadas aleatórias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos uma função auxiliar para gerar caminhadas aleatórias enviesadas a partir do grafo fornecido com os parâmetros fixos de caminhada aleatória:\n",
    "\n",
    "* `p` - Parâmetro da caminhada aleatória \"p\" que define a probabilidade, \"1/p\", de retornar ao nó de origem\n",
    "* `q` - Parâmetro da caminhada aleatória \"q\" que define a probabilidade, \"1/q\", de se mover para um nó afastado do nó de origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stellargraph.data import BiasedRandomWalk\n",
    "\n",
    "\n",
    "def create_biased_random_walker(graph, walk_num, walk_length):\n",
    "    # Configurações de parâmetros para \"p\" e \"q\":\n",
    "    p = 1.0\n",
    "    q = 1.0\n",
    "    return BiasedRandomWalk(graph, n=walk_num, length=walk_length, p=p, q=q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações de Parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos Node2Vec, Attri2Vec, GraphSAGE e GCN seguindo o mesmo procedimento de aprendizado não supervisionado: primeiro geramos um conjunto de caminhadas aleatórias curtas a partir do grafo fornecido e, em seguida, aprendemos os embeddings dos nós a partir de lotes de pares `target, context` coletados das caminhadas aleatórias. Para aprender os embeddings dos nós, é necessário especificar os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `dimension` - Dimensionalidade dos embeddings dos nós\n",
    "* `walk_number` - Número de caminhadas partindo de cada nó\n",
    "* `walk_length` - Comprimento de cada caminhada aleatória\n",
    "* `epochs` - Número de épocas para treinar o modelo de aprendizado de embeddings\n",
    "* `batch_size` - Tamanho do lote para treinar o modelo de aprendizado de embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos consistentemente a dimensão dos embeddings dos nós como 128 para todos os algoritmos. No entanto, usamos diferentes camadas ocultas para aprender os embeddings dos nós de acordo com os algoritmos, a fim de explorar seus respectivos potenciais. Para os demais parâmetros, configuramos os seguintes valores:\n",
    "\n",
    "|               | Node2Vec | Attri2Vec | GraphSAGE | GCN |\n",
    "|---------------|----------|-----------|-----------|-----|\n",
    "| `walk_number` |    20    |     4     |     1     |  1  |\n",
    "| `walk_length` |     5    |     5     |     5     |  5  |\n",
    "| `epochs`      |    6     |     6     |     6     |  6  |\n",
    "| `batch_size`  |    50    |     50    |    50     |  50 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como todos os algoritmos utilizam os mesmos valores para `walk_length`, `batch_size` e `epochs`, definimos esses parâmetros de forma uniforme aqui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "walk_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 2 # original = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para diferentes algoritmos, os usuários podem encontrar a melhor configuração de parâmetros utilizando o conjunto de arestas de ` Model Selection `."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec\n",
    "\n",
    "Utilizamos o Node2Vec [1] para calcular os embeddings dos nós. Esses embeddings são aprendidos de forma a garantir que nós que estão próximos no grafo permaneçam próximos no espaço de embedding. Treinamos o Node2Vec com os componentes do Node2Vec fornecidos pelo Stellargraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph.mapper import Node2VecLinkGenerator, Node2VecNodeGenerator\n",
    "from stellargraph.layer import Node2Vec, link_classification\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def node2vec_embedding(graph, name):\n",
    "\n",
    "    # Set the embedding dimension and walk number:\n",
    "    dimension = 128\n",
    "    walk_number = 20\n",
    "\n",
    "    print(f\"Training Node2Vec for '{name}':\")\n",
    "\n",
    "    graph_node_list = list(graph.nodes())\n",
    "\n",
    "    # Create the biased random walker to generate random walks\n",
    "    walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
    "\n",
    "    # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
    "    unsupervised_samples = UnsupervisedSampler(\n",
    "        graph, nodes=graph_node_list, walker=walker\n",
    "    )\n",
    "\n",
    "    # Define a Node2Vec training generator, which generates batches of training pairs\n",
    "    generator = Node2VecLinkGenerator(graph, batch_size)\n",
    "\n",
    "    # Create the Node2Vec model\n",
    "    node2vec = Node2Vec(dimension, generator=generator)\n",
    "\n",
    "    # Build the model and expose input and output sockets of Node2Vec, for node pair inputs\n",
    "    x_inp, x_out = node2vec.in_out_tensors()\n",
    "\n",
    "    # Use the link_classification function to generate the output of the Node2Vec model\n",
    "    prediction = link_classification(\n",
    "        output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"dot\"\n",
    "    )(x_out)\n",
    "\n",
    "    # Stack the Node2Vec encoder and prediction layer into a Keras model, and specify the loss\n",
    "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        metrics=[keras.metrics.binary_accuracy],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        generator.flow(unsupervised_samples),\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        use_multiprocessing=False,\n",
    "        workers=4,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Build the model to predict node representations from node ids with the learned Node2Vec model parameters\n",
    "    x_inp_src = x_inp[0]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "\n",
    "    # Get representations for all nodes in ``graph``\n",
    "    node_gen = Node2VecNodeGenerator(graph, batch_size).flow(graph_node_list)\n",
    "    node_embeddings = embedding_model.predict(node_gen, workers=1, verbose=0)\n",
    "\n",
    "    def get_embedding(u):\n",
    "        u_index = graph_node_list.index(u)\n",
    "        return node_embeddings[u_index]\n",
    "\n",
    "    return get_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attri2Vec\n",
    "\n",
    "Utilizamos o Attri2Vec [2] para calcular os embeddings dos nós. O Attri2Vec aprende as representações dos nós realizando um mapeamento linear/não-linear nas características de conteúdo dos nós e, simultaneamente, garantindo que nós que compartilham contextos similares em caminhadas aleatórias tenham representações similares. Como as características de conteúdo dos nós são utilizadas para aprender os embeddings, esperamos que o Attri2Vec alcance um desempenho superior na predição de links em comparação com o Node2Vec, que preserva apenas a estrutura da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stellargraph.mapper import Attri2VecLinkGenerator, Attri2VecNodeGenerator\n",
    "from stellargraph.layer import Attri2Vec\n",
    "\n",
    "\n",
    "def attri2vec_embedding(graph, name):\n",
    "\n",
    "    # Set the embedding dimension and walk number:\n",
    "    dimension = [128]\n",
    "    walk_number = 4\n",
    "\n",
    "    print(f\"Training Attri2Vec for '{name}':\")\n",
    "\n",
    "    graph_node_list = list(graph.nodes())\n",
    "\n",
    "    # Create the biased random walker to generate random walks\n",
    "    walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
    "\n",
    "    # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
    "    unsupervised_samples = UnsupervisedSampler(\n",
    "        graph, nodes=graph_node_list, walker=walker\n",
    "    )\n",
    "\n",
    "    # Define an Attri2Vec training generator, which generates batches of training pairs\n",
    "    generator = Attri2VecLinkGenerator(graph, batch_size)\n",
    "\n",
    "    # Create the Attri2Vec model\n",
    "    attri2vec = Attri2Vec(\n",
    "        layer_sizes=dimension, generator=generator, bias=False, normalize=None\n",
    "    )\n",
    "\n",
    "    # Build the model and expose input and output sockets of Attri2Vec, for node pair inputs\n",
    "    x_inp, x_out = attri2vec.in_out_tensors()\n",
    "\n",
    "    # Use the link_classification function to generate the output of the Attri2Vec model\n",
    "    prediction = link_classification(\n",
    "        output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    "    )(x_out)\n",
    "\n",
    "    # Stack the Attri2Vec encoder and prediction layer into a Keras model, and specify the loss\n",
    "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        metrics=[keras.metrics.binary_accuracy],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        generator.flow(unsupervised_samples),\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        use_multiprocessing=False,\n",
    "        workers=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Build the model to predict node representations from node features with the learned Attri2Vec model parameters\n",
    "    x_inp_src = x_inp[0]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "\n",
    "    # Get representations for all nodes in ``graph``\n",
    "    node_gen = Attri2VecNodeGenerator(graph, batch_size).flow(graph_node_list)\n",
    "    node_embeddings = embedding_model.predict(node_gen, workers=1, verbose=0)\n",
    "\n",
    "    def get_embedding(u):\n",
    "        u_index = graph_node_list.index(u)\n",
    "        return node_embeddings[u_index]\n",
    "\n",
    "    return get_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE\n",
    "\n",
    "O GraphSAGE [3] aprende os embeddings dos nós em grafos atribuídos através da agregação das características dos nós vizinhos. Os parâmetros de agregação são aprendidos incentivando pares de nós que coocorrem em caminhadas aleatórias curtas a terem representações similares. Como as características dos nós também são aproveitadas, espera-se que o GraphSAGE apresente um desempenho superior ao Node2Vec na predição de links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stellargraph.mapper import GraphSAGELinkGenerator, GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE\n",
    "\n",
    "\n",
    "def graphsage_embedding(graph, name):\n",
    "\n",
    "    # Set the embedding dimensions, the numbers of sampled neighboring nodes and walk number:\n",
    "    dimensions = [128, 128]\n",
    "    num_samples = [10, 5]\n",
    "    walk_number = 1\n",
    "\n",
    "    print(f\"Training GraphSAGE for '{name}':\")\n",
    "\n",
    "    graph_node_list = list(graph.nodes())\n",
    "\n",
    "    # Create the biased random walker to generate random walks\n",
    "    walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
    "\n",
    "    # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
    "    unsupervised_samples = UnsupervisedSampler(\n",
    "        graph, nodes=graph_node_list, walker=walker\n",
    "    )\n",
    "\n",
    "    # Define a GraphSAGE training generator, which generates batches of training pairs\n",
    "    generator = GraphSAGELinkGenerator(graph, batch_size, num_samples)\n",
    "\n",
    "    # Create the GraphSAGE model\n",
    "    graphsage = GraphSAGE(\n",
    "        layer_sizes=dimensions,\n",
    "        generator=generator,\n",
    "        bias=True,\n",
    "        dropout=0.0,\n",
    "        normalize=\"l2\",\n",
    "    )\n",
    "\n",
    "    # Build the model and expose input and output sockets of GraphSAGE, for node pair inputs\n",
    "    x_inp, x_out = graphsage.in_out_tensors()\n",
    "\n",
    "    # Use the link_classification function to generate the output of the GraphSAGE model\n",
    "    prediction = link_classification(\n",
    "        output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    "    )(x_out)\n",
    "\n",
    "    # Stack the GraphSAGE encoder and prediction layer into a Keras model, and specify the loss\n",
    "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        metrics=[keras.metrics.binary_accuracy],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        generator.flow(unsupervised_samples),\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        use_multiprocessing=False,\n",
    "        workers=4,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Build the model to predict node representations from node features with the learned GraphSAGE model parameters\n",
    "    x_inp_src = x_inp[0::2]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "\n",
    "    # Get representations for all nodes in ``graph``\n",
    "    node_gen = GraphSAGENodeGenerator(graph, batch_size, num_samples).flow(\n",
    "        graph_node_list\n",
    "    )\n",
    "    node_embeddings = embedding_model.predict(node_gen, workers=1, verbose=0)\n",
    "\n",
    "    def get_embedding(u):\n",
    "        u_index = graph_node_list.index(u)\n",
    "        return node_embeddings[u_index]\n",
    "\n",
    "    return get_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN\n",
    "\n",
    "O GCN [4] aprende os embeddings dos nós por meio de convolução em grafos. Tradicionalmente, o GCN depende de rótulos dos nós como supervisão para realizar o treinamento. Aqui, consideramos o cenário de predição de links não supervisionada e tentamos aprender embeddings de nós informativos no GCN, garantindo que nós que coocorrem em caminhadas aleatórias curtas sejam representados de forma próxima, como é feito no treinamento do GraphSAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stellargraph.mapper import FullBatchLinkGenerator, FullBatchNodeGenerator\n",
    "from stellargraph.layer import GCN, LinkEmbedding\n",
    "\n",
    "\n",
    "def gcn_embedding(graph, name):\n",
    "\n",
    "    # Set the embedding dimensions and walk number:\n",
    "    dimensions = [128, 128]\n",
    "    walk_number = 1\n",
    "\n",
    "    print(f\"Training GCN for '{name}':\")\n",
    "\n",
    "    graph_node_list = list(graph.nodes())\n",
    "\n",
    "    # Create the biased random walker to generate random walks\n",
    "    walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
    "\n",
    "    # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
    "    unsupervised_samples = UnsupervisedSampler(\n",
    "        graph, nodes=graph_node_list, walker=walker\n",
    "    )\n",
    "\n",
    "    # Define a GCN training generator, which generates the full batch of training pairs\n",
    "    generator = FullBatchLinkGenerator(graph, method=\"gcn\")\n",
    "\n",
    "    # Create the GCN model\n",
    "    gcn = GCN(\n",
    "        layer_sizes=dimensions,\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        generator=generator,\n",
    "        dropout=0.3,\n",
    "    )\n",
    "\n",
    "    # Build the model and expose input and output sockets of GCN, for node pair inputs\n",
    "    x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "    # Use the dot product of node embeddings to make node pairs co-occurring in short random walks represented closely\n",
    "    prediction = LinkEmbedding(activation=\"sigmoid\", method=\"ip\")(x_out)\n",
    "    prediction = keras.layers.Reshape((-1,))(prediction)\n",
    "\n",
    "    # Stack the GCN encoder and prediction layer into a Keras model, and specify the loss\n",
    "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        metrics=[keras.metrics.binary_accuracy],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    batches = unsupervised_samples.run(batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}\")\n",
    "        batch_iter = 1\n",
    "        for batch in batches:\n",
    "            samples = generator.flow(batch[0], targets=batch[1], use_ilocs=True)[0]\n",
    "            [loss, accuracy] = model.train_on_batch(x=samples[0], y=samples[1])\n",
    "            output = (\n",
    "                f\"{batch_iter}/{len(batches)} - loss:\"\n",
    "                + \" {:6.4f}\".format(loss)\n",
    "                + \" - binary_accuracy:\"\n",
    "                + \" {:6.4f}\".format(accuracy)\n",
    "            )\n",
    "            if batch_iter == len(batches):\n",
    "                print(output)\n",
    "            else:\n",
    "                print(output, end=\"\\r\")\n",
    "            batch_iter = batch_iter + 1\n",
    "\n",
    "    # Get representations for all nodes in ``graph``\n",
    "    embedding_model = keras.Model(inputs=x_inp, outputs=x_out)\n",
    "    node_embeddings = embedding_model.predict(\n",
    "        generator.flow(list(zip(graph_node_list, graph_node_list)))\n",
    "    )\n",
    "    node_embeddings = node_embeddings[0][:, 0, :]\n",
    "\n",
    "    def get_embedding(u):\n",
    "        u_index = graph_node_list.index(u)\n",
    "        return node_embeddings[u_index]\n",
    "\n",
    "    return get_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar e avaliar o modelo de predição de links\n",
    "\n",
    "Existem algumas etapas envolvidas no uso dos embeddings aprendidos para realizar a predição de links:\n",
    "1. Calculamos os embeddings de links/arestas para as amostras de arestas positivas e negativas aplicando um operador binário nos embeddings dos nós de origem e destino de cada aresta amostrada.\n",
    "2. Dado os embeddings dos exemplos positivos e negativos, treinamos um classificador de regressão logística para prever um valor binário indicando se uma aresta entre dois nós deve ou não existir.\n",
    "3. Avaliamos o desempenho do classificador de links para cada um dos 4 operadores nos dados de treinamento com os embeddings dos nós calculados no **Grafo de Treinamento** (`graph_train`) e selecionamos o melhor classificador.\n",
    "4. O melhor classificador é então usado para calcular os escores nos dados de teste com os embeddings dos nós treinados no **Grafo de Treinamento** (`graph_train`).\n",
    "\n",
    "Abaixo estão um conjunto de funções auxiliares que nos permitem repetir essas etapas para cada um dos operadores binários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 1. link embeddings\n",
    "def link_examples_to_features(link_examples, transform_node, binary_operator):\n",
    "    return [\n",
    "        binary_operator(transform_node(src), transform_node(dst))\n",
    "        for src, dst in link_examples\n",
    "    ]\n",
    "\n",
    "\n",
    "# 2. training classifier\n",
    "def train_link_prediction_model(\n",
    "    link_examples, link_labels, get_embedding, binary_operator\n",
    "):\n",
    "    clf = link_prediction_classifier()\n",
    "    link_features = link_examples_to_features(\n",
    "        link_examples, get_embedding, binary_operator\n",
    "    )\n",
    "    clf.fit(link_features, link_labels)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def link_prediction_classifier(max_iter=5000):\n",
    "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
    "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
    "\n",
    "\n",
    "# 3. and 4. evaluate classifier\n",
    "def evaluate_link_prediction_model(\n",
    "    clf, link_examples_test, link_labels_test, get_embedding, binary_operator\n",
    "):\n",
    "    link_features_test = link_examples_to_features(\n",
    "        link_examples_test, get_embedding, binary_operator\n",
    "    )\n",
    "    score = evaluate_roc_auc(clf, link_features_test, link_labels_test)\n",
    "    return score\n",
    "\n",
    "\n",
    "def evaluate_roc_auc(clf, link_features, link_labels):\n",
    "    predicted = clf.predict_proba(link_features)\n",
    "\n",
    "    # check which class corresponds to positive links\n",
    "    positive_column = list(clf.classes_).index(1)\n",
    "    return roc_auc_score(link_labels, predicted[:, positive_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos 4 operadores diferentes:\n",
    "\n",
    "* *Hadamard*\n",
    "* $L_1$\n",
    "* $L_2$\n",
    "* *average*\n",
    "\n",
    "O artigo [1] fornece uma descrição detalhada desses operadores. Todos os operadores produzem embeddings de links com a mesma dimensionalidade dos embeddings de entrada dos nós (128 dimensões no nosso exemplo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def operator_hadamard(u, v):\n",
    "    return u * v\n",
    "\n",
    "\n",
    "def operator_l1(u, v):\n",
    "    return np.abs(u - v)\n",
    "\n",
    "\n",
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "\n",
    "def operator_avg(u, v):\n",
    "    return (u + v) / 2.0\n",
    "\n",
    "\n",
    "def run_link_prediction(binary_operator, embedding_train):\n",
    "    clf = train_link_prediction_model(\n",
    "        examples_train, labels_train, embedding_train, binary_operator\n",
    "    )\n",
    "    score = evaluate_link_prediction_model(\n",
    "        clf,\n",
    "        examples_model_selection,\n",
    "        labels_model_selection,\n",
    "        embedding_train,\n",
    "        binary_operator,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"classifier\": clf,\n",
    "        \"binary_operator\": binary_operator,\n",
    "        \"score\": score,\n",
    "    }\n",
    "\n",
    "\n",
    "binary_operators = [operator_hadamard, operator_l1, operator_l2, operator_avg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinar e avaliar o modelo de links com o embedding especificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding, name):\n",
    "\n",
    "    embedding_train = embedding(graph_train, \"Train Graph\")\n",
    "\n",
    "    # Train the link classification model with the learned embedding\n",
    "    results = [run_link_prediction(op, embedding_train) for op in binary_operators]\n",
    "    best_result = max(results, key=lambda result: result[\"score\"])\n",
    "    print(\n",
    "        f\"\\nBest result with '{name}' embeddings from '{best_result['binary_operator'].__name__}'\"\n",
    "    )\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            [(result[\"binary_operator\"].__name__, result[\"score\"]) for result in results],\n",
    "            columns=(\"name\", \"ROC AUC\"),\n",
    "        ).set_index(\"name\")\n",
    "    )\n",
    "\n",
    "    # Evaluate the best model using the test set\n",
    "    test_score = evaluate_link_prediction_model(\n",
    "        best_result[\"classifier\"],\n",
    "        examples_test,\n",
    "        labels_test,\n",
    "        embedding_train,\n",
    "        best_result[\"binary_operator\"],\n",
    "    )\n",
    "\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletar os resultados da predição de links para Node2Vec, Attri2Vec, GraphSAGE e GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph.nodes()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Obter o resultado da predição de links com Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Node2Vec for 'Train Graph':\n",
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10039/10039 - 58s - loss: 0.5486 - binary_accuracy: 0.6733 - 58s/epoch - 6ms/step\n",
      "Epoch 2/2\n"
     ]
    }
   ],
   "source": [
    "node2vec_result = train_and_evaluate(node2vec_embedding, \"Node2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter o resultado da predição de links com Attri2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(graph_train.node_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri2vec_result = train_and_evaluate(attri2vec_embedding, \"Attri2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter o resultado da predição de links com GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_result = train_and_evaluate(graphsage_embedding, \"GraphSAGE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter o resultado da predição de links com GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_result = train_and_evaluate(gcn_embedding, \"GCN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparação entre Node2Vec, Attri2Vec, GraphSAGE e GCN no conjunto de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pontuações de ROC AUC no conjunto de teste de links para diferentes embeddings com seus respectivos melhores operadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        (\"Node2Vec\", node2vec_result),\n",
    "        (\"Attri2Vec\", attri2vec_result),\n",
    "        (\"GraphSAGE\", graphsage_result),\n",
    "        (\"GCN\", gcn_result),\n",
    "    ],\n",
    "    columns=(\"name\", \"ROC AUC\"),\n",
    ").set_index(\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este exemplo demonstrou como usar a biblioteca `stellargraph` para construir um algoritmo de predição de links para grafos homogêneos utilizando embeddings não supervisionados aprendidos por Node2Vec [1], Attri2Vec [2], GraphSAGE [3] e GCN [4].\n",
    "\n",
    "Para mais informações sobre o processo de predição de links, todos esses algoritmos possuem demonstrações específicas com mais detalhes:\n",
    "\n",
    "- [Node2Vec](node2vec-link-prediction.ipynb)\n",
    "- [Attri2Vec](attri2vec-link-prediction.ipynb)\n",
    "- [GraphSAGE](graphsage-link-prediction.ipynb)\n",
    "- [GCN](gcn-link-prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/link-prediction/homogeneous-comparison-link-prediction.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/link-prediction/homogeneous-comparison-link-prediction.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
